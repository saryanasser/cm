---
title: "My Computational Musicology Dashboard"
author: "saryanasser"
date: "Block 4 - 2025"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: cosmo
---
```{r setup, include=FALSE}
library(tidyverse)
library(flexdashboard)
library(plotly)
```

### CLass Corpus Tempi Histogram
```{r}
library(tidyverse)

# Load the dataset
compmus_data <- read_csv("compmus2025.csv")

# Create a histogram of the "tempo" column
ggplot(compmus_data, aes(x = tempo)) +
  geom_histogram(binwidth = 5, fill = "deeppink4", color = "black") +
  labs(title = "Histogram of Tempi in Class Corpus",
       x = "Tempo (BPM)",
       y = "Count") +
  theme_minimal()

```

***

There is a clear peak around 90-100 BPM, suggesting that this is the most frequent tempo range in the class corpus. It is also interesting that there are multiple peaks, suggesting that there is a diverse set of tempos rather than a single dominant one. There are also some tracks in the lower tempo range (below 50 BPM), possibly due to half-time interpretations.



### Tempogram Energy Novelty
```{r}
library(tidyverse)
source("compmus.R")
"features/reinout-w-2.json" |>
  compmus_energy_novelty() |> 
  ggplot(aes(t, novelty)) +
  geom_line() +
  theme_minimal() +
  labs(x = "Time (s)", y = "Energy Novelty")
```

***

The ``compmus_energy_novelty()` function estimates novelty based on sudden changes in loudness over time. It detects significant shifts in energy levels, which are useful for identifying musical onsets and transitions. For this particular track, there are evident onsets at approximately 10 and 70 seconds.



### Cepstrogram Spectral Novelty
```{r}
library(tidyverse)
source("compmus.R")
"features/reinout-w-2.json" |>
  compmus_spectral_novelty() |> 
  ggplot(aes(t, novelty)) +
  geom_line() +
  theme_minimal() +
  labs(x = "Time (s)", y = "Spectral Novelty")
```

***

The `compmus_spectral_novelty()` function approximates spectral novelty by analyzing cepstrograms, which represent changes in the frequency content of a signal, detecting harmonic or timbral shifts better than energy-based novelty. Because this visualization seems more consistent that that of the energy novelty, it can be deduced that there is less spectral variation and more energy novelty. 






### tempograms
```{r}
library(gridExtra)
regular_tempogram <- "features/reinout-w-2.json" |>
  compmus_tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(option = "rocket", guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Regular Tempogram") +
  theme_dark()

cyclic_tempogram <- "features/reinout-w-2.json" |>
  compmus_tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(option = "rocket", guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Cyclic Tempogram") +
  theme_dark()

grid.arrange(regular_tempogram, cyclic_tempogram, ncol = 2)
```

***

The regular tempogram shows several tempo harmonics (observable lines at increasing bpm values of 150, 300, 450). This suggests that the music contains strong rhythmic subdivisions, reinforcing multiple layers of the base tempo. The high presence of harmonics suggests a steady and rhythmic beat structure, likely because it is an electronic / techno track. The lack of tempo variation over time indicates that the tempo remains stable throughout the track.
On the other hand, the cyclic tempogram shows a dominant tempo of around 150 bpm, with a weaker subharmonic at around 110 bpm. 


### Keygram

```{r}
library(tidyverse)
source("compmus.R")
#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
"features/reinout-w-2.json" |> 
  compmus_chroma(norm = "identity") |> 
  compmus_match_pitch_templates(
    key_templates,         # Change to chord_templates if desired
    norm = "manhattan",       # Try different norms (and match it with what you used in `compmus_chroma`)
    distance = "cosine"   # Try different distance metrics
  ) |>
  ggplot(aes(x = time, y = name, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(option = "rocket", guide = "none") +            # Change the colours?
  labs(x = "Time (s)", y = "Template", fill = NULL) +
  theme_dark()                                      # Change the theme?

```

***

Using the 1–0 coding for the chord templates, I generated a Keygram for Reinout's second track. This Keygram makes use of the new helper function `compmus_match_pitch_templates`, which compares the averaged chroma vectors against templates. Generally, a keygram shows the progression of chords over time by matching chroma features (pitch class profiles) to predefined chord templates. The visualization represents which chords are most likely at each point in time. For instance, for the chosen track, dark colors, such as at the start of the track and around the 70-80 second range, represent short distances / differences between the recorded chords and the template. keygrams help identify harmonic progressions, modulations, and changes in harmony over time.

### Keygram using Temperley's proposed improvements

```{r}
library(tidyverse)
source("compmus.R")
#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(5.0, 2.0, 3.5, 2.0, 4.5, 4.0, 2.0, 4.5, 2.0, 3.5, 1.5, 4.0) #Temperley's revised C major keys
minor_key <-
  c(5.0, 2.0, 3.5, 4.5, 2.0, 4.0, 2.0, 4.5, 3.5, 2.0, 1.5, 4.0) #Temperley's revised C minor keys

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
"features/reinout-w-2.json" |> 
  compmus_chroma(norm = "identity") |> 
  compmus_match_pitch_templates(
    key_templates,         
    norm = "manhattan",       # Try different norms (and match it with what you used in `compmus_chroma`)
    distance = "cosine"   # Try different distance metrics
  ) |>
  ggplot(aes(x = time, y = name, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(option = "rocket", guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = "Template", fill = NULL) +
  theme_light()                                      # Change the theme?
```

***

This is the same keygram generateed using Temperley's proposed improvements. It reveals more or less similar insights, but generally, Temperely's improvements imply clearer or more stable key regions, assign higher weights to stable scale degrees (tonic, dominant), and reflect more natural tonal hierarchies 

### Chordogram

```{r}
library(tidyverse)
source("compmus.R")
#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
"features/reinout-w-2.json" |> 
  compmus_chroma(norm = "identity") |> 
  compmus_match_pitch_templates(
    chord_templates,         # Changed to chord_templates to create chordogram
    norm = "manhattan",       # Try different norms (and match it with what you used in `compmus_chroma`)
    distance = "cosine"   # Try different distance metrics
  ) |>
  ggplot(aes(x = time, y = name, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(option = "rocket", guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = "Template", fill = NULL) +
  theme_light()                                      # Change the theme?
```


### Chroma-based self-similarity

```{r}
source("compmus.R")
"features/reinout-w-2.json" |>                           # Change the track
  compmus_chroma(norm = "chebyshev") |>                 # Change the norm
  compmus_self_similarity(
    feature = pc,
    distance = "cosine"                             # Change the distance
  ) |>   
  ggplot(aes(x = xtime, y = ytime, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(option = "mako", guide = "none") +  # Change color scale          
  labs(x = "Time (s)", y = NULL, fill = NULL) +
  theme_dark()                                      # Change the theme?
```

### Timbre-based self-similarity

```{r}
source("compmus.R")
"features/reinout-w-2.json" |>    
  compmus_mfccs(norm = "identity") |>                  # Change the norm
  compmus_self_similarity(
    feature = mfcc,
    distance = "euclidean"                             # Change the distance
  ) |>   
  ggplot(aes(x = xtime, y = ytime, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(option = "turbo", guide = "none")   +            # Change the colours?
  labs(x = "Time (s)", y = NULL, fill = NULL) +
  theme_dark()   
```

***

Chroma- vs Timbre- based self-similarity:

Timbre features, often represented by MFCCs (Mel-Frequency Cepstral Coefficients), capture the spectral characteristics of the sound. This timbre-based self-similarity chart highlights instrumental changes and overall sound quality / production shifts.The effectiveness of chroma- or timbre-based self-similarity for structural analysis depends on the specific characteristics of the track: While the chroma-based self-similarity captures harmonic progressions, tonal structure, key changes, and chord progressions (providing clearer structural pictures for tracks with harmonic content such as pop , jazz and classical music),  timbre-based self-similarity captures instrumental texture and sound quality, outlining changes in orchestration, dynamics, and articulation. Because my chosen track is a more electronic / EDM song, its timbre features are at the forefront, making the timbre-based self-similarity chart more insightful. The timbre-based self-similarity chart portrays the tracks repeated instrumental sections through the prominent diagonal lines with sudden shifts indicating timbral changes (the introduction of new instruments)

### Introduction

Welcome to my Computational Musicology portfolio for 2025! This storyboard contains my perspective on the examples from each week.


![Portfolio 2025, credits; https://www.google.com/url?sa=i&url=http%3A%2F%2Fgyulabodonyi.com%2Fmusic-visualization%2F&psig=AOvVaw3R141Xm5ROKzaMw0YacZhl&ust=1740153548874000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCKiX7-rP0osDFQAAAAAdAAAAABAE](/Users/saryanasser/Library/CloudStorage/OneDrive-UvA/Computational Musicology/music_visualisation.jpg){width=500px}


### Visualising the AI Song Contest

```{r}
aisc2024 <- read_csv("/Users/saryanasser/Library/CloudStorage/OneDrive-UvA/Computational Musicology/saryanasser/aisc2024.csv")
aisc2024 |>                   # Start with the data
  ggplot(                     # Set up the plot.
    aes(
      x = tempo,
      y = arousal,
      size = instrumentalness,
      colour = danceability
    )
  ) +
  geom_point() +              # Scatter plot.
  geom_rug(linewidth = 0.1) + # Add 'fringes' to show data distribution.
  geom_text(                  # Add text labels from above.
    x = 121,
    y = 4.91,
    label = "Onda Corta - Sud America",
    size = 3,                 # Override size (not loudness here).
    hjust = "left",           # Align left side of label with the point.
    vjust = "center",         # Align vertical centre of label with the point.
    angle = 30                # Rotate the text label
  ) +
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(50, 200),
    breaks = c(50, 100, 150, 200), # Specify grid lines
    minor_breaks = NULL       # Remove 'minor' grid lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(1, 9),
    breaks = c(1, 5, 9),
    minor_breaks = NULL
  ) +
  scale_colour_viridis_c() +  # Use the popular viridis colour palette.
  scale_size_continuous(      # Fine-tune the sizes of each point.
    trans = "exp",            # Use an exp transformation to emphasise loud..
    guide = "none"            # Remove the legend for size.
  ) +
  theme_light() +             # Use a simpler theme.
  labs(                       # Make the titles nice.
    x = "Tempo",
    y = "Arousal",
    colour = "Danceability"
  )
ggplotly()
```

***

This is the bad visualisation of the AI Song Contest we used in our first lab session, this time in a dashboard.

### Visualising the AI Song Contest 2

```{r}
aisc2024 |> 
  ggplot(aes(x = tempo, y = arousal, color = danceability)) +
  geom_point(alpha = 0.7, aes(size = instrumentalness)) +  # Add transparency for visibility
  geom_smooth(method = "loess", color = "black", linetype = "dashed", se = FALSE) +  # Trend line for clarity
  scale_x_continuous(
    limits = c(50, 200),
    breaks = seq(50, 200, by = 50)
  ) +
  scale_y_continuous(
    limits = c(1, 9),
    breaks = c(1, 5, 9)
  ) +
  scale_color_viridis_c(option = "plasma") +  # Use a distinct, high-contrast palette
  scale_size(range = c(1, 6)) +  # Keep point sizes meaningful
  theme_minimal(base_size = 14) +  # Cleaner theme with larger text
  labs(
    title = "AI Song Contest 2024: Tempo vs. Arousal",
    subtitle = "Danceability indicated by color, instrumentalness by size",
    x = "Tempo (BPM)",
    y = "Arousal (Energy Level)",
    color = "Danceability",
    size = "Instrumentalness"
  ) +
  theme(legend.position = "bottom")  # Move legend to avoid overlap
ggplotly()
```
***
To improve and build upon the first visualization, I sought to formulate a story by improving the look of the visualization, making it more readable. I went about doing this by:

1. Removing elements like `geom_rug()` that did not add much value  
2. Adjusting labels, font sizes, and layout to improve clarity  
3. Adding trend lines or facets for better pattern recognition, enhancing comparisons  
4. Using the size and color variables in a meaningful way  

This updated version:  

✅ Clearly shows tempo vs. arousal trends  
✅ Uses color and size effectively  
✅ Highlights overall trends with a dashed trend line  
✅ Has a clean and readable layout  

### compmus120125 corpus 

```{r}
compmus2025 <- read_csv("/Users/saryanasser/Library/CloudStorage/OneDrive-UvA/Computational Musicology/saryanasser/compmus2025.csv")
compmus2025 |> 
  ggplot(aes(x = tempo, y = arousal, color = danceability)) +
  geom_point(alpha = 0.7, aes(size = instrumentalness)) +  # Transparency for visibility
  geom_smooth(method = "loess", color = "black", linetype = "dashed", se = FALSE) +  # Trend line
  scale_x_continuous(limits = c(50, 200), breaks = seq(50, 200, by = 50)) +
  scale_y_continuous(limits = c(1, 9), breaks = c(1, 5, 9)) +
  scale_color_viridis_c(option = "plasma") +  # High-contrast palette
  scale_size(range = c(1, 6)) +  # Meaningful point sizes
  theme_dark(base_size = 14) +  # More readable theme
  labs(
    title = "Computational Musicology Corpus 2025: Tempo vs. Arousal",
    subtitle = "Danceability indicated by color, instrumentalness by size",
    x = "Tempo (BPM)",
    y = "Arousal (Energy Level)",
    color = "Danceability",
    size = "Instrumentalness"
  ) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 12),  # Center & bold title
    plot.subtitle = element_text(hjust = 0.5, size = 14),  # Center subtitle
    plot.margin = margin(10, 10, 10, 10),  # Adds padding
    legend.position = "bottom",
    legend.box = "vertical"
  )  
```


### Personal track descriptions

I decided on exploring different genres that I like by asking different models for various genres of songs. I have always been a fan of post-punk, alternative rock music from the late 90s to early 2000s, such as Interpol, The Strokes, Bloc Party, Arctic Monkeys, Fontaines D.C. With the help of AI, I came up with this description to use as a prompt for gen AI music models: a high-energy alt rock / post-punk song with a melodic bassline, intricate drumming, and sharp and rhythmic guitar work, reminiscent of the bands Interpol and Bloc Party. dynamic, with tension-building verses leading into an explosive, anthemic chorus. create a sense of depth and intensity.” I also used this shortened version for models with character limits “Post-Punk, Driving Melodic Bassline, Angular Reverb-Drenched Guitars, Punchy Dynamic Drumming, Moody Detached Vocals, Urgent & Anthemic, Dark Yet Energetic, Tension-Building Composition, 140 BPM”. I have also recently been enjoying deep house music, so I decided to choose this genre as one of my songs. I used the following prompts, “deep house song that has a hypnotic beat, gradually layering warm synths, deep basslines, and subtle percussive beats, with a steady, entrancing rhythm. slow, cinematic build-ups that evoke nostalgia and euphoria. Incorporate atmospheric pads and a shimmering, time-dissolving feel of the track, with immersive, and emotionally uplifting verses and bridges, suitable for a sunset in the mountains” and “Deep House, Hypnotic Synth Pads, Pulsing Bassline, Rolling Four-on-the-Floor Groove, Atmospheric Textures, Slow-Building Progression, Dreamy Vocal Samples, Cinematic, Nostalgic, Expansive, 120 BPM”. I wanted to try a different genre that I also enjoy, something along the lines of Lana del Rey’s style. So I used the following prompts, “A cinematic baroque / dream pop composition that blends dreamy electronic synths with classical orchestration. Feature violins, melancholic clarinets, and rich trumpet swells, weaving through ethereal synth pads and delicate, reverberated piano. The rhythm should be slow and hypnotic, with a hazy, dreamlike quality. The vocals should be intimate yet grand, drenched in vintage-style reverb, with poetic, melancholic lyrics evoking themes of romance, nostalgia, and faded Hollywood glamour. Think of Lana Del Rey’s storytelling style, but with a modern dream pop twist—layered harmonies, sweeping crescendos, and an air of cinematic longing .” and “Baroque Pop / Dream Pop, Ethereal Synth Pads, Sweeping Violin & Clarinet Arrangements, Melancholic Trumpet Swells, Reverb-Drenched Intimate Vocals, Vintage Aesthetic, Poetic & Nostalgic, Cinematic & Grand, 80 BPM”. I explored the outputs of these prompts from various models including Suno, Stable Audio, Beatoven.ai, Soundverse.ai, Udio, and Mubert. Although I was hesitant to try Suno and Udio given their use of artists’ music without compensating them, I wanted to see whether there would be any differences in the quality, production output, relevance to the prompt, and similarity to expectations and existing songs. I ended up deciding on the Stable Audio deep house track because it seemed to best match my expectations of emotive, intense, while also calming and not sounding too elaborate. I found the vocal and lyrical qualities of most models to be of somewhat lower quality than I was expecting, with many songs sounding unnatural or AI generated (understandably). I ended up deciding to go with another deep house song that I generated on Suno.  

### Chromogram of a colleague's song 

```{r}
source("compmus.R")
"features/reinout-w-2.json" |>                           
  compmus_chroma(norm = "manhattan") |>                
  ggplot(aes(x = time, y = pc, fill = value)) + 
  geom_raster() +
  scale_y_continuous(
    breaks = 0:11,
    minor_breaks = NULL,
    labels = c(
                "C", "C#", "D", "D#",
                "E", "F", "F#", "G",
                "G#", "A", "A#", "B"
              )
  ) +
   scale_fill_viridis_c(option = "rocket", guide = "none") +             
  labs(x = "Time (s)", y = NULL, fill = NULL) +
  theme_light()                                      

```

***

The Essentia features of my own tracks were not available for analysis, so for the basis of the following visualizations, I used a fellow student's tracks, Reinout W, which I personally enjoyed, found intriguing, and was curious what computational analysis may reveal about. This chromagram of a Reinout's second track, which reveals the distribution of the 12 musical pitch classes of the selected song. It shows relatively high instances of the C, D, E, G, and A pitch classes, with lower instances of the C#/Db, D#/Eb, F, F#Gb, G#/Ab, and A#/Bb classes. A chromagram represents pitch class content regardless of octave, making it useful for identifying harmonic structure and key

I modified the template code by:

1. Changing the `norm` parameter, which affects how the chroma features are normalized: I chose the `manhattan` norm to retain musical structure
2. Changing the theme and color scales: For personalization and variation on the visual clarity, I used the rocket coolor scale and the light theme option


### Cepstrogram 

```{r}
source("compmus.R")
"features/reinout-w-2.json" |>                           # Change the track
  compmus_mfccs(norm = "euclidean") |>                  # Change the norm
  ggplot(aes(x = time, y = mfcc, fill = value)) + 
  geom_raster() +
  scale_y_continuous(
    breaks = 0:12,
    minor_breaks = NULL,
  ) +
  scale_fill_viridis_c(option = "rocket", guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = "Coefficient Number", fill = NULL) +
  theme_dark() 
```

***

This cepstrogram of the same track reveals a visual representation of the cepstrum of a signal over time, used for timbre analysis. It works by: computing a spectrogram (amplitude of a Fourier transform), then applying a second inverse Fourier Transform (cepstrum) -  which is the result of the logarithm of the estimated signal spectrum

I modified the template code by:

1. Changing the `norm` parameter, which affects how the chroma features are normalized: I chose the `euclidean` norm, sued for high-dimensional data and to emphasize clarity.
2. Changing the theme and color scales: For personalization and variation on the visual clarity, I used the rocket color scale and the dark theme option


### Conclusion / Discussion

incomplete
